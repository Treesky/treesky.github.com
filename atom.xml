<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Running]]></title>
  <link href="http://Treesky.github.com/atom.xml" rel="self"/>
  <link href="http://Treesky.github.com/"/>
  <updated>2015-08-22T22:56:06+08:00</updated>
  <id>http://Treesky.github.com/</id>
  <author>
    <name><![CDATA[Treesky]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A Secant Version of the L-M Method]]></title>
    <link href="http://Treesky.github.com/blog/2015/08/22/a-secant-version-of-the-l-m-method/"/>
    <updated>2015-08-22T15:45:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2015/08/22/a-secant-version-of-the-l-m-method</id>
    <content type="html"><![CDATA[<p>在优化的时候，基于梯度的的一系列算法是最常用的，但是还有一些情况下，我们的目标函数的梯度无法计算，这时候就需要用到 Secant version的一些算法了，比如 Secant version 的 L-M 算法。</p>

<p>函数的 Jacobian 矩阵计算方式如下：</p>

<script type="math/tex; mode=display">
\mathbf{J} (x) = \left[ \cfrac{\partial f_i }{\partial x_j} \right]
</script>

<p>牛顿法有两个缺陷：</p>

<p>1）Jacibian 矩阵的计算过于复杂，需要计算 <script type="math/tex">m*n</script> 次；同时在函数形式未知的情况下，需要很多的努力来估计 Jacobian 矩阵。</p>

<p>2）牛顿法在实践中，需要一个非常好的初始化点来收敛，而这个是不太容易满足的。</p>

<p>因此为了解决这个问题，出现了一系列的方法来减少对 Jacobian 矩阵的计算次数，可以做到只在初始的时候计算一次。</p>

<script type="math/tex; mode=display">
\cfrac{\partial f_i }{\partial x_j} (\mathbf{x}) \approx \cfrac{f_i( \mathbf{x}+ \delta \mathbf{e}_j) - f_i(\mathbf{x})}{\delta} = b_{ij}
</script>

<p><script type="math/tex">\mathbf{e}_j</script> 是第 j 维为 0 的 unit vector. 在这种计算法方法下，每一轮我们需要 n+1 次 <script type="math/tex">f(x) </script>, 这是一种非常没有效率的做法。</p>

<p>Now consider</p>

<script type="math/tex; mode=display">
\mathbf{f} (\mathbf{x}+\mathbf{h}) \approx \mathbf{l}(\mathbf{h}) = \mathbf{f} (\mathbf{x}) + \mathbf{J}(\mathbf{x}) \mathbf{h}
</script>

<p>由于我们无法确切知道 <script type="math/tex">\mathbf{J}(\mathbf(x))</script>，所以我们使用矩阵 <script type="math/tex">\mathbf{B}</script> 来近似。即：</p>

<script type="math/tex; mode=display">
\mathbf{f} (\mathbf{x}+\mathbf{h}) \approx \mathbf{l}(\mathbf{h}) = \mathbf{f} (\mathbf{x}) + \mathbf{B} \mathbf{h}
</script>

<p>通过泰勒展式展开可得</p>

<script type="math/tex; mode=display">
f(x+h) = f(x) + Bh
</script>

<p>在这个式子中我们待求得是B，已知的是<script type="math/tex">f(x+h), f(x), h</script>, 所以这个有 n*n 个未知数和 n 个式子。因此 <script type="math/tex">B</script> 是无法求解的。</p>

<p>为了解决这个问题，Broydon(1965) 提出一个新的条件，即 <script type="math/tex">B_{new}</script> 和 <script type="math/tex">B</script> 尽可能的相似。
所以我们解决的问题就变成了</p>

<script type="math/tex; mode=display">
min ||B-B_{old}||

st. f(x+h) = f(x) + Bh
</script>

<p>这个问题有两种解释：</p>

<p>1、 在满足切线方程(<script type="math/tex"> f(x+h) - f(x) =  Bh </script>, 这也是题目中 secant version 的由来)的前提之下，最小化 <script type="math/tex">B</script> 和 <script type="math/tex">B</script> 之间的  Frobenius norm diff.</p>

<p>2、第二种解释就是在 <script type="math/tex">h</script> 所在的 <script type="math/tex">n</script> 维空间中，有n个方向，和 <script type="math/tex">\|\|B_{old}\|\|</script>  在对 <script type="math/tex"> \|\|h\|\|</script> 进行变换的过程中，只能在 <script type="math/tex">h</script> 所在的方向上不同，在其他的基方向上，表现都应该相同。所以在其他 <script type="math/tex">n-1</script> 个方向 <script type="math/tex">v</script> 上，都应该满足 <script type="math/tex">Bv = B_{old}v</script>, 这样就有了额外 <script type="math/tex">n-1</script> 个方程。所以一共联立起 <script type="math/tex">n^2</script> 个方程，即可求解。</p>

<p>不管是基于 norm 求解的解释，还是基于空间基向量的表示，我们对上述问题进行求解之后，都可以得到一个解即</p>

<script type="math/tex; mode=display">
B=B_{old}+uh^T

h=x-x_{old}, u = \cfrac{1}{h^Th}(f(x)-f(x_old)-Bh)
</script>

<p>在我们可以得到新的B之后，我们就可以套用传统的 L-M 方法，或者其他的 quasi-Newton 法来解目标问题了。a</p>

<p>这里我们将这个计算方法套入 L-M 算法当中就得到了 Secant Version 的 L-M 算法。</p>

<p>算法伪代码如下：</p>

<p><img src="http://farm6.staticflickr.com/5786/20167391413_d5b6320014_b.jpg" alt="" /></p>

<pre><code> %SMARQUARDT  Secant version of Levenberg-Marquardt's method for least   
 % Version 10.11.08.  hbn(a)imm.dtu.dk
 
 % Check parameters and function call
 f = NaN;  ng = NaN;  perf = [];  B = [];
 info = zeros(1,7);
 if  nargin &lt; 2,  stop = -1;
 else
   [stop x n] = checkx(x0);   
   if  ~stop
 [stop f r] = checkrJ(fun,x0,varargin{:});  info(6) = 1;
 if  ~stop
   %  Finish initialization
   if  nargin &lt; 3,  opts = []; end
   opts  = checkopts('smarquardt', opts);  % use default options where required
   tau = opts(1);tolg = opts(2);  tolx = opts(3);  relstep = opts(5);  
   if  opts(4) &gt; 0,  maxeval = opts(4); else,  maxeval = 100 + 10*n; end
   % Jacobian
   if  nargin &gt; 3  % B0 is given
 sB = size(B0);  m = length(r);
 if  sum(sB) == 0  % placeholder
   [stop B] = Dapprox(fun,x,relstep,r,varargin{:});  
   info(6) = info(6) + n;
 elseif  any(sB ~= [m n]),  stop = -4;
 else,  B = B0;   end
   else
 [stop B] = Dapprox(fun,x,relstep,r,varargin{:});  
 info(6) = info(6) + n;
   end
   % Check gradient and J'*J   
   if  ~stop
 g = B'*r;   ng = norm(g,inf);  A = B'*B;
 if  isinf(ng) | isinf(norm(A(:),inf)),  stop = -5; end 
   end
 end
   end
 end
 if  stop
   X = x0;  info([1:5 7]) = [f ng  0  tau  0 stop];
   return
 end
 
 % Finish initialization
 mu = tau * max(diag(A));
 Trace = nargout &gt; 2;
 if  Trace
   o = ones(1, maxeval);  
   X = x * o;  perf = [f; ng; mu] * o;
 end 
 
 % Iterate
 k = 1;   nu = 2;   nh = 0;
 ng0 = ng;
 ku = 0;   % direction of last update
 kit = 0;  % no. of iteration steps
 
 while  ~stop
   if  ng &lt;= opts(2),  stop = 1; 
   else 
 [h mu] = geth(A,g,mu);
 nh = norm(h);   nx = tolx + norm(x);
 if  nh &lt;= tolx*nx,  stop = 2; end 
   end 
   if  ~stop
 xnew = x + h;h = xnew - x;  
 [stop fn rn] = checkrJ(fun,xnew,varargin{:});  info(6) = info(6)+1;
 if  ~stop
   % Update  B
   ku = mod(ku,n) + 1; 
   if  abs(h(ku)) &lt; .8*norm(h)  % extra step
 xu = x;
 if  x(ku) == 0,  xu(ku) = opts(5)^2;
 else,xu(ku) = x(ku) + opts(5)*abs(x(ku)); end
 [stop fu ru] = checkrJ(fun,xu,varargin{:});  info(6) = info(6)+1;
 if  ~stop
   hu = xu - x;
   B = B + ((ru - r - B*hu)/norm(hu)^2) * hu';
 end
   end
   B = B + ((rn - r - B*h)/norm(h)^2) * h'; 
   k = k + 1;
   dL = (h'*(mu*h - g))/2;   
   if  length(rn) ~= length(r)
 df = f - fn;
   else  % more accurate
 df = ( (r - rn)' * (r + rn) )/2; 
   end 
   if  (dL &gt; 0) &amp; (df &gt; 0)   % Update x and modify mu  
 kit = kit + 1;   
 x = xnew;   f = fn;  r = rn;
 mu = mu * max(1/3, 1 - (2*df/dL - 1)^3);   nu = 2;
 if  Trace
   X(:,kit+1) = x;   perf(:,kit+1) = [fn norm(B'*rn,inf) mu]'; end
   else  % Same  x, increase  mu
 mu = mu*nu;  nu = 2*nu; 
   end 
   if  info(5) &gt; maxeval,  stop = 3; 
   else
 g = B'*r;  ng = norm(g,inf);  A = B'*B;
 if  isinf(ng) | isinf(norm(A(:),inf)),  stop = -5; end
   end
 end  
   end
 end
 %  Set return values
 if  Trace
   ii = 1 : kit+1;  X = X(:,ii);   
   perf = struct('f',perf(1,ii), 'ng',perf(2,ii), 'mu',perf(3,ii));
 else,  X = x;  end
 if  stop &lt; 0,  tau = NaN;  else,  tau = mu/max(diag(A)); end
 info([1:5 7]) = [f  ng  nh  tau  kit stop];
</code></pre>

<p>当hessian矩阵为正定的时候，驻点为最小值；负定的时候为最大值；既有正的特征值又有负的特征值的时候，为鞍点</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[reverse_bit]]></title>
    <link href="http://Treesky.github.com/blog/2015/04/01/reverse-bit/"/>
    <updated>2015-04-01T22:24:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2015/04/01/reverse-bit</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Factorization machine]]></title>
    <link href="http://Treesky.github.com/blog/2014/04/10/factorization-machine/"/>
    <updated>2014-04-10T17:00:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/04/10/factorization-machine</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Context Advertisment]]></title>
    <link href="http://Treesky.github.com/blog/2014/04/10/context-advertisment/"/>
    <updated>2014-04-10T16:59:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/04/10/context-advertisment</id>
    <content type="html"><![CDATA[<p>上下文广告广告系统</p>

<p>在”标准”的上下文广告系统中，我们以一次 pv 作为广告检索的出发点，即我们把一次 pv 作为一个广告检索的 case， 然后在这个过程中我们对这样一个 case 做出触发、CTR预估、排序。</p>

<p>这样一种 case 的建立，即以一次pv作为一次广告检索出发点是否合理呢？</p>

<p>我们知道搜索广告和联盟广告的一个重要区别在于搜索广告有着极强的触发信号，即每一次 pv 作为广告检索的 case 来理解，来触发，CTR预估，排序等等。而在联盟广告中，唯一的触发信号就是网民。如果我们在每一次联盟广告的检索过程中，都要经过触发，ctr预估，排序的话不仅会增加很多的运算代价，同时也忽略了网民在前后点击之间的关系。</p>

<p>如果说以单次pv作为触发信号，对上下文广告来说，可能粒度确实过细了。</p>

<p>如果对比搜索广告的话，搜索广告以一个query作为一个触发信号，因此我们以query触发方式来构建整个检索系统，是合乎情理的。
对应的，如果说联盟广告以网民作为触发信号的话，那么是不是应该在每一个网民上作为建立触发、预估、排序呢？我觉得这是一个非常有意思的topic。</p>

<p>即以用户为中心的广告检索系统。</p>

<p>以网民为中心的广告检索系统，需要的是我们对网民的”兴趣”的一个理解。因此我们需要一个线下的挖掘技术来挖掘网民的需求。如何分析网民的需求呢？</p>

<p>总的思路就是 网民 和 广告主 是广告系统的两端。
1、我们能覆盖到的网民 同时我们也有的广告主 是我们的核心流量。也是最重要的部分。
2、能覆盖到的网民，没有对应的广告主的部分，这部分是我们的重点拓展方向。
3、有广告主，但是没有对应的网民部分，这部分是没办法的事情。</p>

<p>Q2的point在如何分析 我们同时能覆盖到的网民和广告主，以及二者之间的关联
网民：需要一个全网的覆盖数据。
4 主要分析广告主对应的网民。
	4.1 挑选核心网民(对核心账户贡献较多的网民)。
	4.2 累计这些网民的浏览数据/query数据等互联网foot print.
5 对网民的行为轨迹中，分析特征
	5.1 分析网民的foot print数据，形成特征。
	5.2 从这些特征出发，泛化分析额外的用户/作为新的触发特征。
6 对网民和广告主之间关系进行分析。
	6.1 给这些用户推荐合适的广告
	6.2 backup</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[logistic regression]]></title>
    <link href="http://Treesky.github.com/blog/2014/04/10/logistic-regression/"/>
    <updated>2014-04-10T16:58:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/04/10/logistic-regression</id>
    <content type="html"><![CDATA[<p>logistic regression 的 prob 的定义是</p>

<script type="math/tex; mode=display">
p(y=1|x)=\cfrac{1}{1+e^{- \mathbf{w} \mathbf{x}}} \\
p(y=-1|x)=\cfrac{1}{1+e^{\mathbf{w} \mathbf{x}}}
</script>

<p>整体loss是max-liklihood
$$
f(w) =  \sum log( {1+e^{-y \mathbf{w} \mathbf{x}}} )
$$</p>

<p>一阶倒数为
$$
\begin{aligned}
\cfrac{ \partial f}{\partial w_i} = \sum \cfrac{-y x_i}{1+e^{y \mathbf{w} \mathbf{x}}} <br />
 &amp;= \sum ((\cfrac{1}{1+e^{ - y \mathbf{w} \mathbf{x}}} - 1) y x_i)
\end{aligned}
$$ </p>

<p>二阶倒数为
$$
\cfrac{\partial f}{\partial w_i \partial w_j} = \sum \cfrac{x_i x_j}{(1+e^{-y \mathbf{w} \mathbf{x}}) (1+e^{y \mathbf{w} \mathbf{x}})}
$$</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[margin_auc]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/19/dist-auc/"/>
    <updated>2014-02-19T13:26:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/19/dist-auc</id>
    <content type="html"><![CDATA[<p>最近在想一些关于评价标准的问题，就是什么是一个 “好” 的分类器。机器学习中关于好的定义和标准有很多，比如最早的 accuracy，之后的 precision，recall，F1等等。不同的应用方法体现了我们对 <strong>好</strong> 这个概念的不同认识。</p>

<pre><code>事实上在一个真实的机器学习问题中，如何确定一个 “好” 的概念，是最困难和重要的部分。
</code></pre>

<p>随着机器学习应用的发展，现实中很多应用都有着类别不平衡等各种问题，比如在广告点击率预估的问题中，clk 和 noclk 之间的数据差别是很大的，即使是凤巢首条广告 10%+ 的点击率，也依然有着较为严重的类别不平衡的问题； 这就导致了 precision 等评价指标并不能代表现实应用意义上的好。于是机器学习界引入了 AUC 作为评价指标。</p>

<p>AUC 的全称应该是 Area Under ROC Cruve. 就是 ROC 曲线的线下面积。ROC曲线则是以(TPR，FPR) 的点作为连线，画出的一条曲线。</p>

<script type="math/tex; mode=display">
TPR = \cfrac{TP}{TP+FN} \\
FPR = \cfrac{FP}{FP+TN}
</script>

<p>在分类问题中这种计算方法，其实就是我们把决策面在测试集中不停的移动，然后看在不同的决策面下，判定为 + 的那些 instance 中，有多少是真的正例(TP)，有多少是假的正例（FP）。比如在广告预估系统中，我们预估出一个 instance 被点击的概率 p，然后我们不停的改变判定为点击的 p 的阈值，比如第一次计算 p_threshold = 0.9 的情况下，我们计算所有 p &gt; 0.9 的 instance 中，有多少 instance 是真的点击，而有多少的 instance是未点击。然后经过 (TP+FN, FP+TN) 的归一化之后就是一个点。然后我们不停的改变 p_threshold 的阈值得到一系列点，最后把这些点连成 ROC 曲线，计算 ROC 曲线线下面积，得到AUC。</p>

<p>这种计算方法隐含的一个假设就是 <strong>排在最前面的那些 instance 的准确性是最重要的</strong>，因为在累加计算的过程中，第一个点总会累加到后面的所有点上，因此头部的正确性是非常重要的。而在实际应用的过程中（比如广告和视频推荐），我们会发现其实排在最前面的那些 instance 之间的相对关系来说，并不是最重要的。比如广告A 和 广告B 的预估 CTR 分别为 0.9 和 0.8，其实我们根本不关注 0.9 和 0.8 这两个 instance 谁更重要，因为这两个广告如果高的预估CTR， 不管谁比谁更高，最终都是会展现出去的。真正值得我们关心的是在分界面附近的那些广告， 即该广告的展现和不展现都是在模棱两可的时候，如果我们的分类器能把这些 case 给区分的比较清楚，这才是真正的善莫大焉。</p>

<p>因此我们计算一个 dist-auc, 也就是对原始的 auc 做一些计算上的改变，我们从分界面附近的分类器算起，从分界面往两边计算，计算出一个整体的 auc 出来，这样就可以使得模型的计算方法和我们的线上效果之间的关系更加密切。</p>

<p>回过头来看，这种不关心远离分界面之间的 instance 的计算方法，其实有点类似 margin 的思路，那么是不是如果我们使用 hinge-loss，来代替常规的 log-loss，在广告预估系统上会取得一个更好的效果呢？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[owlqn]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/19/owlqn/"/>
    <updated>2014-02-19T01:09:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/19/owlqn</id>
    <content type="html"><![CDATA[<p>在我们优化一个 loss function 的时候最自然的想法就是 gradient descent，毕竟 gradient 指向的是在当前点上的最速下降方向。</p>

<p>但是 gradient descent 的 local convergence 的速度非常慢，这部分是因为 gradient descent 是一种 “贪婪” 的做法，每次的时候我们都只考虑当前点的最速下降方向。</p>

<p>除了 梯度 方向之外，还有很多方向可以用来作为搜索方向。这里面最有名的可能就是 Newton direction。</p>

<p>Newton direction 考虑了如下问题</p>

<script type="math/tex; mode=display">
f(x_k + p) \approx f_k + p^T \nabla f_k + \cfrac{1}{2} p^T \nabla ^2 f_k p = m_k(p)
</script>

<p>当前的点是 $x_k$ 我们需要考虑的问题就是如果让 $x_k$ 在方向 $p$ 上移动单位长度，使得我们的函数值变的更小。
我们对 $f(x_k + p) $ 做二阶泰勒展式展开，就可以得到等号右边的形式。然后对这个泰勒展示导数 = 0，可以得到</p>

<script type="math/tex; mode=display">
p = -\nabla ^2 f_k^{-1} \nabla f_k
</script>

<p>牛顿法在 local convergence 阶段有很好的收敛速度，但是 $ \nabla ^2 f_k $ 也就是我们所说的 hessian 矩阵，求解起来特别麻烦，于是我们就想通过一些近似的方法来求解 $ \nabla ^2 f_k $</p>

<p>一个简单的思路就是，二阶导数是一阶导数的导数，也就是说</p>

<script type="math/tex; mode=display">
\nabla ^2 f_k^{-1} = B_{k+1} (x_{k+1} - x_k) = \nabla f_{k+1} - \nabla f_k 
</script>

<p>令 </p>

<script type="math/tex; mode=display">
s_k = x_ {k+1} - x_k \\
y_k = \nabla f_{k+1} - \nabla f_k 
</script>

<p>我们就得到 $B_{k+1} s_k = y_k$ 这就是著名的切线公式。</p>

<p>注意我们在得到 newton direction 的过程中，需要的一个条件就是hessian 矩阵正定；同是考虑到，求偏导次序不影响结果，因此hessian 矩阵还有正对称的性质。</p>

<p>满足 $B_{k+1} s_k = y_k$ 的矩阵有无数，这个方程有 $n^2$ 的自由度，考虑到对称的性质，这个方程还有 $n(n-1)/2$ 的自由度；正定的性质可以额外引入 $n$ 个约束，即所有的 principal minors 应该是正的。但是这依然不足以唯一确定满足切线方程的矩阵。因此我们<strong>强行</strong> 引入了一个需求，就是 $B$ 和 $B_k$ 尽量“相似”</p>

<script type="math/tex; mode=display">
\min \limits _B \| B - B_k \| \\
\text{subject to   } B = B^T, B s_k = y_k
</script>

<p>根据 “相似性” 也就是 norm 的定义不同，我们可以得到不同的 伪牛顿法，这里的相似性定义是<code>Frobenius norm</code>:</p>

<script type="math/tex; mode=display">
\| A \| _w = \| W^{1/2}AW{1/2} ||_F
</script>

<script type="math/tex; mode=display">
 \| C \| ^2_F = \sum _{i=1}^n \sum _{j=1}^n c_{ij}^2
</script>

<p>$W$ 的选择只要满足 $W y_k = S_k$ 即可。</p>

<p>这里我们取 $W = G_k^{-1}$</p>

<script type="math/tex; mode=display">
G_k = [ \int_0^1 \nabla ^2 f(x_k + m \alpha _k p_k) dm]
</script>

<p>确定了 norm 的定义之后，我们求解 $B_k$ 就可以得到 DFP 伪牛顿法如下：</p>

<script type="math/tex; mode=display">
B_{k+1} = (I - r_k y_k s_k ^T) B_k (I - r_k s_k y_k ^T) + r_k y_k y_k^T, \\
r_k = \cfrac{1}{y_k^T s_k}.
</script>

<p>考虑到我们最终用的时候，用的是 $B_k^{-1}$ 而不是 $B_k$ 本身，因此我们可以考虑直接近似 $B_k^{-1}$ 而不是近似 $B_k$ 然后再求逆矩阵。即我们直接求解 $H_{k+1} y_k = s_k$</p>

<script type="math/tex; mode=display">
\min \limits_H \| H - H_k \| \\
\text{subject to } H = H^T, H y_k = s_k.
</script>

<p>一样的 norm 求解得到</p>

<script type="math/tex; mode=display">
H_{k+1} = (I - \rho _k s_k y_k^T)H_k(I- \rho _k y_k s_k^T) + \rho _k s_k s_k^T, \\
\rho _k = \cfrac{1}{y_k^T s_k}
</script>

<p>这就是著名的BFGS算法。可能BFGS算法是所有的伪牛顿法中，普遍来说效果比较好的。</p>

<p>BFGS算法虽然很好，但是要存储 $H_{k+1}$ 这个矩阵的大小是 $n(n+1)/2$ ，这个空间在 $n$ 很大的时候，是难以接受的。</p>

<p>通过分析 BFGS 的更新公式，我们可以看到每次更新都只依赖于 $H_k, s_k, y_k$，如果我们把之前的 $H_0, 以及每一步的s_k, y_k$ 都保存下来的话，每次使用的时候，我们就可以现算出一个 $r = H_k \nabla f_k$ 的向量出来。</p>

<p>通过精心的算法设计，就得到了LBFGS two-loop recursion 算法
<code>http://www.cnblogs.com/downtjs/archive/2013/07/29/3222643.html</code></p>

<p>再接下来就是通过使用 sub gradient 代替 gradient，解决了 l1-norm 不可导的问题之后，就得到了 OWL-QN 算法。 </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[model_selection]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/11/model-selection/"/>
    <updated>2014-02-11T23:32:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/11/model-selection</id>
    <content type="html"><![CDATA[<p>mostly from <code>Ensemble Methods: Foundations and Algorithms</code></p>

<p>为了得到一个泛化能力强的模型，我们通常使用 cross-validation  + test error 来选择模型，但是交叉验证也不避免的会受到随机分割的数据集的影响。（也就是说，不同的数据集分割方法关于哪个模型的泛化能力更强，是会给出不同的答案的。）这时候我们就是使用一些假设检验的方法的帮助我们确定“模型A的效果优于模型B”，这个结论是否可信。</p>

<p>在交叉验证的假设检验中，我们最常使用的就是 10-fold cross-validation t-test.</p>

<p>10-fold cross-validation 就是随机把数据分成10份，然后9份训练，一份做测试，进而得到两个算法在10个测试集上的不同表现。</p>

<p>t-test 是从 z-test 中改进得到的，z-test 适用于样本量较大的时候，在样本量较小的时候，z-test有很大的误差，由于我们是 10-fold  validation 因此在假设检验的时候，我们只有10个样本，因此我们需要采用 t-test. t-test 需要满足一个条件，样本本身（即classifier 在检验集上的错误率/其他评价指标）服从高斯分布（在样本数量较大的情况下，即使不服从高斯分布，也可以使用t-test）。</p>

<p>在 Dependent-Samples t-test中，我们计算
$$
t = \cfrac{\sum \limits _{i=1}^n D_i}{\sqrt{\cfrac{n\sum \limits _{i=1}^n D_i^2 - (\sum \limits _{i=1}^n D_i)^2}{n-1}}}
$$</p>

<p>$D_i$ 表示在相同的 validation set 下的两个算法评测结果的差异。</p>

<p>通过如上计算的 t-值，以及给定的显著性水平 $ \alpha $ ，我们就可以得到拒绝阈 $ | t | $，并进而得到我们是否接受 $ H_0 $ 假设，也就是两个算法是否有差异。</p>

<p>但是 Dietterich[1998] 中指出 10-fold cross-validation t-test 会得到一个较小的 variability 并进一步会在两个算法没有差异的情况下，错误地认为两个算法有差异。因此 Dietterich 推荐使用 5*2 cross-validation paired t-test.</p>

<p>在5*2的 cross-validation 中，每次我们把数据集平均分成2份，两个算法分别在某一份上做训练，然后在另外一份数据上做测试，于是我们就得到四个错误率 $err_a^{(1)}, err_a^{(2)}, err_b^{(1)}, err_b^{2}$， $a，b$ 表示不同算法，$1,2$ 表示训练集。 $d^{(i)} = err_a^{(i)} - err_b^{(i)}$，然后计算均值和方差：</p>

<script type="math/tex; mode=display">
\mu = \cfrac{d^{(1)} + d^{(2)}}{2}
</script>

<script type="math/tex; mode=display">
s^2 = (d^{(1)} - \mu ) ^2 + (d^{(2)} - \mu)^2
</script>

<p>我们给 $\mu s^2$ 加上下标 $i$ 表示第 $i$ 次cross-validation（一共5次）
我们如下计算 t-值</p>

<script type="math/tex; mode=display">
\tilde t = \cfrac{d_1^{(1)}}{\sqrt{\cfrac{1}{5}\sum \limits _{i=1}^5 s_i^2}} ~ t_5
</script>

<p>如果我们只有一次检验机会的话，比如 1*2 cross-validation（看起来好诡异的样子）的话，我们也可以使用  <strong>McNemar’s test</strong> 方法，也就是</p>

<script type="math/tex; mode=display">
\cfrac{(|err_{ab}-err_{ba}|-1)^2}{err_{ab} + err_{ba}} \sim X_1^2
</script>

<p>$ err<em>{ab} $ 表示 $a$ 预测正确，而 $b$ 预测错误的个数， 相应的 $err</em>{ba}$ 表示 $b$ 预测正确，而 $a$ 预测错误的个数。</p>

<p>如果我们要在多个测试集上验证多个算法的话，我们可以采用 <strong>Friedman test</strong>.这需要我们使用 <em>Nemenyi post-hoc test</em> [Demsar, 2006] 来计算 <em>critical differnce value</em></p>

<script type="math/tex; mode=display">
CD = q_{\alpha} \sqrt{\cfrac{K(K+1)}{6N}}
</script>

<p>$N$ 是测试用数据集的数量， $K$ 是算法的数量， $q_{\alpha}$ 是 <em>critical value</em>. 两个算法之间如果在【数据集上的表现的rank值】的平均 的差大于 $CD$ 值的话，就认为有显著差异。</p>

<p>我个人认为后面介绍的 <strong>critical difference diagram</strong> 会更加直观。就是每个算法一个bar，bar的中心中心是该算法在所有数据集上表现的rank值的平均，bar的宽度是 <em>critical difference value</em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Adaboost 漫谈]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/11/ensemble/"/>
    <updated>2014-02-11T23:24:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/11/ensemble</id>
    <content type="html"><![CDATA[<p>from <code>Ensemble Methods: Foundations and Algorithms</code></p>

<p>提到 ensemble 类的算法，第一个要提到的就是 boosting, boosting 类算法的最初诞生，来自于 Kearns and Valiant [1989]提出的一个理论上的问题，就是 <em>weakly learnalbe 和 strongly learnable 这两类问题是否等价</em>，由于在现实应用中，一个 weakly 的分类器总是很容易得到的，但是一个 strongly 的分类器却很难得到，因此如果上面那个问题的答案是 “是” 的话，那么任何一个弱分类器都有潜力成为一个强分类器。因此上述理论问题的答案，对真实应用有着相当程度的指导意义。Schapire [1990] 通过构造的方法，回答上上面的问题，构造出来的算法框架就是 boosting. </p>

<p>在 boosting 类算法中，最有名的就属 adaboost 了。 Friedman [2000] 的出发点就是最小化 <strong>exponential loss</strong></p>

<script type="math/tex; mode=display">
l_{exp}(h \| D) = E_{x ～ D} [e^{-f(x)h(x)}]
</script>

<p>我们首先解释为什么使用 <strong>exponential loss</strong></p>

<script type="math/tex; mode=display">
\cfrac{\partial e^{-f(x)H(x)}}{\partial H(x)} = -f(x) e^{-f(x)}H(x)
</script>

<p>$H(x)$ 是我们要求的模型，$f(x)$ 代表真实的分布函数，$f(x)$ 的取值在分类的情况下，只有两种 ${-1,+1}$，因此</p>

<script type="math/tex; mode=display">
-f(x) e^{-f(x)H(x)} = -e^{-H(x)}P(f(x)=1 \| x) + e^{H(x)} P(f(x)=-1 \| x)
</script>

<p>在优化的过程中，我们强制如上的 $ \text{log loss } = 0$ 的时候，可以得到如下的解</p>

<script type="math/tex; mode=display">
H(x) = \cfrac{1}{2} ln \cfrac{P(f(x) = 1 \| x)}{P(f(x) = -1 \| x)}
</script>

<p>因此</p>

<script type="math/tex; mode=display">
sign(H(x)) = sign(\cfrac{1}{2} ln \cfrac{P(f(x) = 1 \| x)}{P(f(x) = -1 \| x)})
</script>

<p>也就是当 $P(f(x)=1 | x) &gt; P(f(x)=-1 | x)$ 的时候 $sign(H(x)) = 1$，而 $P(f(x)=1 | x) &lt; P(f(x)=-1 | x)$ 的时候 $sign(H(x)) = -1$，而这个结果就是贝叶斯分类器的结果，也就是理论上的最优结果。</p>

<p>因此我们就得出结论，<strong>优化 log loss 和 优化bayesian 分类错误率是一致的</strong>，而这也是 Adaboost 的所有的出发点。</p>

<p>Adaboost 在整个算法过程中主要分为两步，第一步 <strong>求得$h_t(x)$的权重$\alpha_t$</strong> ，第二步在 <strong>$H_t$ 的基础上求得一个新的 <script type="math/tex">h_{t+1}</script></strong> ，使得新的 $h_{t+1}$ 可以弥补 $$H_t$ 的一些不足</p>

<p>在第一步的情况下，我们已经得到了$h_t$，要求得$\alpha _t$使得$\alpha _t * h_t$ 可以最小化 log loss.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{aligned}
l_{exp}(\alpha _t h_t \| D_t) &= E_{x \sim D_t}[e^{-f(x) \alpha _t h_t(x)}] \\
&= e^{-\alpha_t} P_{x \sim D_t}(f(x)= h_t(x)) + e^{\alpha _t} P_{x \sim D_t}(f(x) \ne h_t(x)) \\
&= e^{-\alpha_t}(1-\epsilon _t) + e^{\alpha _t} \epsilon _t
\end{aligned}
 %]]&gt;</script>

<p>上式对 $\alpha _t$ 求导之后强制为0，则</p>

<script type="math/tex; mode=display">
\cfrac{\partial l_{exp}(\alpha _t h_t \| D_t)}{\partial \alpha _t} = -e^{-\alpha _t}(1-\epsilon _t) + e^{\alpha _t} \epsilon _t = 0 \\
\alpha_t = \cfrac{1}{2} ln(\cfrac{1-\epsilon _t}{\epsilon _t})
</script>

<p>得到的 $\alpha _t$ 就是 Adaboost 中对基分类器的权重公式。
从这个公式中，我们要可以朴素的看到，这是一个从错误率中计算得到的，正确率越高，则权重越大；准确率越低，则权重越小。从这个角度上来说，也是 make sense 的。</p>

<p>接下来，我们从 $H _{t-1}$ 来计算 $h _t$ ( $H _{t-1}$ 就是前 $t-1$ 轮的基分类器合并成的分类器)，和计算 $\alpha _t$ 一样，我们来最小化 exp loss：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{aligned}
l_{exp}(H_{t-1} + h_t \| D) &= E_{x \sim D}[e^{-f(x)(H_{t-1}(x)+h_t(x))}] \\
&= E_{x \sim D}[e^{-f(x)H_{t-1}(x)} e^{-f(x)h_t(x)}] \\
&= E_{x \sim D}[e^{-f(x)H_{t-1}(x)}(1-f(x)h_t(x)+\cfrac{f(x)^2 h_t(x)^2}{2})]\text{   对 } e^{-f(x)h_t(x)} \text{ 泰勒展开} \\
&= E_{x \sim D}[e^{-f(x)H_{t-1}(x)}(1-f(x)h_t(x) + \cfrac{1}{2})] \text{   注意} f(x)^2 = 1 \text{   } h_t(x)^2 = 1
\end{aligned}
 %]]&gt;</script>

<p>因此最“理想”的 $h_t(x)$ 就是</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{aligned}
h_t(x) &= arg \min \limits _h l_{exp} (H _{t-1} + h \| D) \\
&= arg \min _h E_{x \sim D}[e^{-f(x)H_{t-1}(x)}(1-f(x)h(x) + \cfrac{1}{2})] \\
&= arg \max _h E_{x \sim D}[e^{-f(x)H_{t-1}(x)}f(x)h(x)] \\
&= arg \max _h E_{x \sim D}[\cfrac{e^{-f(x)H_{t-1}(x)}}{E_{x \sim D}[e^{-f(x)H_{t-1}(x)}]} f(x)h(x)]
\end{aligned}
 %]]&gt;</script>

<p>我们让 </p>

<script type="math/tex; mode=display">
D _t(x) = \cfrac{D(x)e^{-f(x)H_{t-1}(x)}}{E_{x \sim D}[e^{-f(x)H_{t-1}(x)}]}
</script>

<p>的话</p>

<script type="math/tex; mode=display">
h_t(x) = arg \max \limits _h E_{x \sim D_t} [f(x)h(x)]
</script>

<p>从 $D$ 到 $D_t$ 的这一步显得非常的巧妙。纵观整个求解 $h_t$ 的过程，我们可以看到首先在 loss 的建立部分，我们是给 $h_t$ 解决 $H_{t-1}$ 不能解决的instance上以额外的权重，使得 $h_t$ 可以改善整个 $H_t$，这是make sense的，也就是说新的分类器更关注于以往的 ensemble 分类器所解决不了的问题。
接下来，用一个 class-imbalance 里面非常常用的技巧，就是instance的loss加权，我们可以通过对 instance 的分布做改变，down-sampling or up-sampling 来达到完全相同的效果。但是经过这样一个简单的变换之后，整个算法的过程就显得简洁而优美。这一步真是非常巧妙。</p>

<p>接下来还有一些收尾工作，就是我们从原始分布 $D$ 得到 $h_t$ 需要的分布 $D_t$，这总还不够优美，我们希望得到一个递推公式，从 $D_{t-1}$ 得到 $D_t$，具体如下</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{aligned}
D_{t+1}(x) &= \cfrac{D(x) e^{-f(x)H_t(x)}}{E_{x \sim D}[e ^{-f(x)H_t(x)}]} \\
&= \cfrac{D(x)e^{-f(x)H_{t-1}(x)e^{-f(x) \alpha_t h_t(x)}}}{E_{x \sim D}[e^{-f(x)H_t(x)}]} \\
&= D_t(x) \cdot e^{-f(x) \alpha _t h_t(x)} \cfrac{E_{x \sim D[e^{-f(x) H_{t-1}(x)}]}}{E_{x \sim D}[e^{-f(x)H_t(x)}]}
\end{aligned}
 %]]&gt;</script>

<p>而上述公式也正是 Adaboost 调整 instance 分布的公式。</p>

<p>从整体上，我们可以看到我们首先证明了 exp loss 和 bayesian 最优错误率的一致性；然后从 exp loss 出发得到了 $ \alpha _t$ 和 $ D _t(h _t) $ 的更新公式。因此我们可以看到 Adaboost 有很强的在训练数据上得到 Bayesian 最优错误率的能力，但是这个达到这个最优错误率是否就意味着不会过拟合，这个我认为还有另外一个必要条件，就是 <strong>训练数据和测试数据的分布一致</strong>， Adaboost 对这个 <strong>一致性</strong> 非常敏感，只要分布稍有差别，就非常容易过拟合，因此当训练数据和测试数据的分布不一致的情况下， 我们就需要一些额外的措施来帮助我们避免过拟合。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[l1r-lr optimization]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/09/l1r-lr-optimization/"/>
    <updated>2014-02-09T18:33:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/09/l1r-lr-optimization</id>
    <content type="html"><![CDATA[<p>在大规模机器学习中，可能最常见的机器学习算法就是 l1-regularized logisic regreesion. 这种算法适用于大规模稀疏数据，上亿维度的feature，只有几十维的非0特征，几十亿的instance。loss-function如下：</p>

<script type="math/tex; mode=display">
\min \limits_{\mathbf{w}} f(\mathbf{w}) = ||\mathbf{w}||_1 + C \sum _{i=1}^{l} log(1+e^{-y \mathbf{w}^T x})
</script>

<p>owlqn是解决l1r-lr的“标准方法”，实现起来简单粗暴有效 =.=</p>

<p>介绍见：http://www.cnblogs.com/downtjs/archive/2013/07/29/3222643.html
源码见：http://research.microsoft.com/en-us/um/people/jfgao/
这个代码里面，同时计算 $f’(\mathbf{w})$ 和 $f(\mathbf{w})$ 的那部分思路还是挺有意思的。</p>

<p>在<code>A comparision of Optimization Methods and Software for Large-Scale L1-regularized Linear Classification</code>里面介绍了另外一些优化方法，比如CDN.</p>

<p>一、BBR算法
BBR(Bayesian Binary Regression)是<code>Large-scale Bayesian logistic regression for text categorization</code>中提出的一种使用trust-region newton methold来解决 coordnate descent 的 subproblem 的方法。</p>

<p>算法的基本思想如下：</p>

<p>step 1: 给定 $\mathbf{w}^1$.</p>

<p>step 2: while true (coordinate descent的外层循环)</p>

<p>step 3: 对 active sets 中的coordinate j (coordinate descent的内层循环)</p>

<p>step 4: 计算 
$$
U _j = C \sum \limits _{i=1}^l x _{ij}^2 F(y _i(\mathbf{w}^{k,j})^T \mathbf{x}_i, \Delta _j |x _{ij}| ) 
$$</p>

<script type="math/tex; mode=display">
F(r, \delta) = 0.25 (|r| \leq \delta)
</script>

<script type="math/tex; mode=display">
F(r, \delta) = \cfrac{1}{2+e^(|r| - \delta) + e^{\delta - |r|}} (otherwise)
</script>

<script type="math/tex; mode=display">
\Delta _j \text{ is the trust-region}
</script>

<p>step 5: 计算
$$
d = \min ( \max( P( - \cfrac{g_j^{‘}(0)}{U_j}, w_j^{k,j}), - \Delta _j) , \Delta _j)
$$</p>

<script type="math/tex; mode=display">
P(z,w) = z \text{ for } (sgn(w+z) = sgn(w))
</script>

<script type="math/tex; mode=display">
P(z,w) = -w \text{ (otherwise)}
</script>

<p>step 6: 更新
$$
\Delta _j = \max (2|d|, \Delta _j / 2)
$$</p>

<p>step2 和 step3 是标准的 coordinate descent 的算法框架。在step4-step6中，解决了这样一个subproblem，就是</p>

<script type="math/tex; mode=display">
\min \limits_{z} g_j(z) = | \mathbf{w} _j + z | - | \mathbf{w} _j| + L(\mathbf{w} + z \mathbf{e} _j ) - L(\mathbf{w})
</script>

<p>这个 subproblem 的解就表示在选定了 coordinate j上我们应该 move 多长的距离。BBR 使用了 trust-region newton method 来解决这个问题。在使用trust-region过程中，我们需要一个函数来在trust-region内逼近原始函数，在BBR中使用了如下函数</p>

<script type="math/tex; mode=display"> g_j(z) = g_j(0) + g_j^{'}(0) z + \cfrac{1}{2} g_j^{''}(\eta z) z^2 </script>

<p>在解这个问题的过程中，有两个地方需要注意。</p>

<p>第一、找到一个”合适”的 $ {U<em>{jz}} $ 使得 
$$
U</em>{jz} \geq g_j^{‘’}(z), \forall |z| \leq \Delta _j 
$$ </p>

<p>$$
\hat g_j(z) = g_j(0) + g_j^{‘}(0)z + \cfrac{1}{2} {U_{jz}}^2
$$
在这种情况下，只要 step $z$ 能优化 $\hat g_j(z)$ 也就是 $\hat g_j(z) \leq \hat g_j(0)$ 就可以证明
$$
g_j(z) - g_j(0) = g_j(z) - \hat g_j(0) \leq \hat g_j(z) - \hat g_j(0) \le 0
$$
也就是能优化 $\hat g_j(z)$ 的step $z$ 也能优化 $g_j(z)$</p>

<p>第二、在 $w_j^{k,j} = 0$ 的时候 $g_j(z)$ 在 $ z = 0$的情况下，是不连续的。因此 $g_j^{‘}(z)$ 是not well-defined的。在这种情况下，定义如下：如果 $L_j^{‘}(0) + 1 \le 0, g_j^{‘}(0) = L_j^{‘}(0)+ 1$ 如果 $L_j^{‘}(0) - 1 \ge 0, g_j^{‘}(0) = L_j^{‘}(0) - 1$。 这种定义和 OWL-QN 的sub-gradient的定义是如出一辙的，是从”目的”出发的一个定义，这样定义可以使得在 $0 \le z \leq -g_j^{‘}(0)/U_j$ 的情况下，使得 $ \hat g _j(0) \le \hat g _j(0)$ 也就是使我们得到一个更好的解。 这个bound的好坏严重影响算法的性能。</p>

<p>二、 Coordinate Descent Method Using One-Dimensional Newton Directions (CDN).</p>

<p>在CDN中，最后一项使用了 $U_j$ 来代替 Hession值。 如果使用Hession值，然后得到 newon direction 的话，在算法收敛到最后的 local convergence 阶段会得到一个更快的收敛速度。
因此问题就变成了优化如下的目标函数
$$
\min \limits_z |w_j^{k,j} + z| - |w_j^{k,j}| + L_j^{‘}(0) z + \cfrac{1}{2} L_j^{‘’}(0)z^2
$$</p>

<p>上面的问题有close-formed solution就是
$$
d = -\cfrac{L^{‘}(0) + 1}{L^{‘’}(0)} \text{ if } L^{‘’}(0) + 1 \leq L_j^{‘’}(0) w_j^{k,j}
$$
$$
d = -\cfrac{L^{‘}(0) - 1}{L^{‘’}(0)} \text{ if } L^{‘’}(0) - 1 \geq L_j^{‘’}(0) w_j^{k,j}
$$
$$
-w_j^{k,j} \text{ otherwise. }
$$</p>

<p>这个算法的里面有两个要注意的地方就是</p>

<p>1、 在计算 $L^{‘}(0)$ 的过程中，作者把 $L^{‘}(0)$ 的计算方法变了一下，和原始的计算方法是一致的，但是应该能快一些。这个技巧在后面计算的 line search 终止条件的时候，同样出现了。</p>

<p>2、 在最后的 line search 过程中，作者处理了一种特殊情况，就是所有的特征值都是正数的时候，作者使用了一个计算较为简单，不需要遍历所有instance的近似终止条件来判断。这在在实现过程中对算法的运行时间，应该也有较大帮助。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[liblinear_usage]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/05/liblinear-usage/"/>
    <updated>2014-02-05T19:12:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/05/liblinear-usage</id>
    <content type="html"><![CDATA[<p>对大规模稀疏数据要加 -l 0
-s6 l1-regularized logistic regression
-g g -n n : to generate the experiment result of CDN with shrinking technique</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[L1LR-Optimization]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/03/l1lr-optimization/"/>
    <updated>2014-02-03T23:28:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/03/l1lr-optimization</id>
    <content type="html"><![CDATA[<p><code>A comparision of Optimization Methods and Software for Large-Scale L1-regularized Linear Classification</code></p>

<p>台大 <strong>林智仁</strong> 的文章，趁春节期间拜读一下。</p>

<p>优化目标是</p>

<script type="math/tex; mode=display">
\min \limits_{\mathbf{w}} \ f(\mathbf{w}) = ||\mathbf{w}||_1 + C \sum \limits_{i=1}^{l}\xi(\mathbf{w};\mathbf{x}_i,y_i)
</script>

<p>对
$$
\xi(\mathbf{w};\mathbf{x}_i,y_i)
$$
的要求是 <strong>非负，且凸，一阶连续可微</strong>(为什么这三个要求？Appendix A表示这样的话，有至少有一个全局最优解)，这里主要讨论的两个loss就是 <strong>log-loss</strong> 和 <strong>l2-loss</strong> .</p>

<h2 id="decomposition">Decomposition类的方法</h2>

<p>每次选择某些维度进行更新</p>

<h3 id="cyclic-coordinate-descent">Cyclic Coordinate Descent</h3>

<p>选择优化维度 <script type="math/tex"> \mathbf{e}_j </script> 之后，通过优化
$$
\min \limits_{z} g_j(z) = f(\mathbf{w} + z \mathbf{e}_j) - f(\mathbf{w}) = |w_j^{k,j} + z| - |w_j^{k,j}| + L_j(z;\mathbf{w}^{k,j}) - L_j(0;\mathbf{w}^{k,j})
$$
从这个式子中，我们可以得到一个重要的信息，即某个维度 <script type="math/tex">\mathbf{e}_j</script> 在当前迭代轮是否有效。有效的意思就是 <script type="math/tex">z=0</script> 是上式的最优解——当<script type="math/tex">z=0</script>是上式的最优解的时候，我们就知道当然轮在当前维度上，不需要移动。<script type="math/tex">z=0</script>是上式的最优解的当且仅当：</p>

<p>$$
L_j^a (0) + 1 = 0, \ w_j^{k,j} &gt; 0
$$
$$
L_j^a (0) - 1 = 0, \ w_j^{k,j} &lt; 0
$$
$$
-1 \leq L_j^a (0) + 1 \leq 1, \ w_j^{k,j} = 0
$$</p>

<p>这个函数在 <script type="math/tex"> z = -w_j </script> 的时候不可微
得到在维度 <script type="math/tex"> \mathbf{e}_j </script> 上移动的距离</p>

<p><code>Large-scale Bayesian logistic regression for text categorization</code> 中提出了BBR方法。BBR使用trust region和 一维牛顿step来解上面的问题。
CDN是扩展自<code>Coordinate descent method for large-scale L2-loss linear SVM</code>的方法，原方法使用一维newton direction+线性搜索来解决上面的问题，目标是l2约束的问题。
<code>A coordinate gradient descent method for nonsmooth convex optimization problems in machine learning</code> 文章中提出了一个通用的decomposition的框架，可以同时选择多个维度计算，CDN是其中的一个特例。</p>

<h3 id="variable-selection-using-gradient-information">Variable selection using Gradient information</h3>
<p>使用梯度信息选择一组变量， Gauss-Southwell rule. 在使用了梯度信息之后，可以缩减迭代轮数，但是因为要计算梯度信息，因此单轮时间变长。
<code>A coordinate gradient descent method for l1-regularized convex optimization</code> 里面就是用了 CGD-GS方法， coordinate gradient descent &amp; Gauss-Southwell rule</p>

<h3 id="active-set">Active Set</h3>
<p>active set method 的特殊之处在于区分了0权重和非0权重特征，使得计算加快。
Grafting就是active set method for Log Loss</p>

<h2 id="section">解带约束的优化</h2>

<h3 id="section-1">光滑约束</h3>

<p>问题转化为
$$
\min \limits_{\mathbf{w}^+,\mathbf{w}^-} \sum _{j=1}^n w_j^+ + \sum _{j=1}^n w_j^- + C \sum _{i=1}^l \xi (\mathbf{w}^+ - \mathbf{w}^-; \mathbf{x}_i, y_i)
$$</p>

<p>subject to 
$$
 w_j^+ \geq 0, w_j^- \geq 0, j = 1,…,n 
$$</p>

<p>这个转化相当巧妙的把不可微的函数，拆了两个可微的函数的和</p>

<p><code>An interior point method for large-scale l1-regularized logistic regression</code> 把这个问题转化为
$$
\min \limits_ {\mathbf{w}, \mathbf{u}} \sum _{j=1}^n u_j + C \sum _{i=1}^l \xi (\mathbf{w}; \mathbf{x} _i, y_i)
$$</p>

<p>subject to
$$
-u_j \leq w_j \leq u_j, j = 1,…,n
$$
然后使用interior point方法来解这个问题。</p>

<h3 id="section-2">不光滑的约束</h3>

<script type="math/tex; mode=display">
\min \limits_ {\mathbf{w}} \sum _{i=1}^l \xi(\mathbf{w};\mathbf{x}_i, y_i)
</script>

<p>subject to</p>

<script type="math/tex; mode=display">
||\mathbf{w}||_1 \leq K.
</script>

<p>Active Set类的方法 <code>The generalized LASSO</code> 也可以被用来解决类似问题，</p>

<h2 id="section-3">其他方法</h2>

<p>EM
随机梯度下降<code>Stochastic methods for l1 regularized loss minimization</code> <code>Sparse online learning via truncated gradient</code>
OWLQN
Hybrid Methods
Quadratic Approximation Followed by coordinate descent
Cutting Plane methods
Approximating L1 regularization by l2 regularization
Solution Path</p>

<p>提供了语法高亮和方便的快捷键功能，给您最好的 Markdown 编写体验。</p>

<p>来试一下：</p>

<ul>
  <li><strong>粗体</strong> (<code>Ctrl+B</code>) and <em>斜体</em> (<code>Ctrl+I</code>)</li>
  <li>引用 (<code>Ctrl+Q</code>)</li>
  <li>代码块 (<code>Ctrl+K</code>)</li>
  <li>标题 1, 2, 3 (<code>Ctrl+1</code>, <code>Ctrl+2</code>, <code>Ctrl+3</code>)</li>
  <li>列表 (<code>Ctrl+U</code> and <code>Ctrl+Shift+O</code>)</li>
</ul>

<!--more-->

<h3 id="section-4">实时预览，所见即所得</h3>

<p>无需猜测您的 <a href="http://markdownpad.com">语法</a> 是否正确；每当您敲击键盘，实时预览功能都会立刻准确呈现出文档的显示效果。</p>

<h3 id="section-5">自由定制</h3>

<p>100% 可自定义的字体、配色、布局和样式，让您可以将 MarkdownPad 配置的得心应手。</p>

<h3 id="markdown-">为高级用户而设计的稳定的 Markdown 编辑器</h3>

<p>MarkdownPad 支持多种 Markdown 解析引擎，包括 标准 Markdown 、 Markdown 扩展 (包括表格支持) 以及 GitHub 风格 Markdown 。</p>

<p>有了标签式多文档界面、PDF 导出、内置的图片上传工具、会话管理、拼写检查、自动保存、语法高亮以及内置的 CSS 管理器，您可以随心所欲地使用 MarkdownPad。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MarkDown Examples]]></title>
    <link href="http://Treesky.github.com/blog/2014/02/03/weiwei/"/>
    <updated>2014-02-03T15:16:00+08:00</updated>
    <id>http://Treesky.github.com/blog/2014/02/03/weiwei</id>
    <content type="html"><![CDATA[<p>这是一个普通段落：</p>

<pre><code>这是一个代码区块。
	撒旦反抗
</code></pre>

<p>Google means $10^{100}$</p>

<p>A Cross Product Formula</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\mathbf{V}_1 \times \mathbf{V}_2 =  \begin{vmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\\
\frac{\partial X}{\partial u} &  \frac{\partial Y}{\partial u} & 0 \\\
\frac{\partial X}{\partial v} &  \frac{\partial Y}{\partial v} & 0
\end{vmatrix}
 %]]&gt;</script>

<!--more-->

<p>The probability of getting $k$ heads when flipping $n$ coins is</p>

<script type="math/tex; mode=display">
P(E) = {n \choose k} p^k (1-p)^{ n-k}
</script>

<h2 id="markdownpad-2">欢迎使用 MarkdownPad 2</h2>

<p><strong>MarkdownPad</strong> 是 Windows 平台上一个功能完善的 Markdown 编辑器。</p>

<h3 id="markdown-">专为 Markdown 打造</h3>

<p>提供了语法高亮和方便的快捷键功能，给您最好的 Markdown 编写体验。</p>

<p>来试一下：</p>

<ul>
  <li><strong>粗体</strong> (<code>Ctrl+B</code>) and <em>斜体</em> (<code>Ctrl+I</code>)</li>
  <li>引用 (<code>Ctrl+Q</code>)</li>
  <li>代码块 (<code>Ctrl+K</code>)</li>
  <li>标题 1, 2, 3 (<code>Ctrl+1</code>, <code>Ctrl+2</code>, <code>Ctrl+3</code>)</li>
  <li>列表 (<code>Ctrl+U</code> and <code>Ctrl+Shift+O</code>)</li>
</ul>

<!--more-->

<h3 id="section">实时预览，所见即所得</h3>

<p>无需猜测您的 <a href="http://markdownpad.com">语法</a> 是否正确；每当您敲击键盘，实时预览功能都会立刻准确呈现出文档的显示效果。</p>

<h3 id="section-1">自由定制</h3>

<p>100% 可自定义的字体、配色、布局和样式，让您可以将 MarkdownPad 配置的得心应手。</p>

<h3 id="markdown--1">为高级用户而设计的稳定的 Markdown 编辑器</h3>

<p>MarkdownPad 支持多种 Markdown 解析引擎，包括 标准 Markdown 、 Markdown 扩展 (包括表格支持) 以及 GitHub 风格 Markdown 。</p>

<p>有了标签式多文档界面、PDF 导出、内置的图片上传工具、会话管理、拼写检查、自动保存、语法高亮以及内置的 CSS 管理器，您可以随心所欲地使用 MarkdownPad。</p>
]]></content>
  </entry>
  
</feed>
